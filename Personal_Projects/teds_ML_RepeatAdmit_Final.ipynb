{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams, gridspec\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/kelsey.huntzberry/Documents/Opioid_Research/Python\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Treatment Episode Data Set data\n",
    "teds1517 = pd.read_csv('/Users/kelsey.huntzberry/Documents/Opioid_Research/Data/TEDS/Raw_Data/tedsa_puf_2015_2017.csv')\n",
    "teds14 = pd.read_csv('/Users/kelsey.huntzberry/Documents/Opioid_Research/Data/TEDS/Raw_Data/tedsa_puf_2014.csv')\n",
    "teds13 = pd.read_csv('/Users/kelsey.huntzberry/Documents/Opioid_Research/Data/TEDS/Raw_Data/tedsa_puf_2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names so data can be appended\n",
    "teds1517 = teds1517.drop(columns = \"FREQ_ATND_SELF_HELP\")\n",
    "teds13 = teds13.drop(columns = \"PMSA\")\n",
    "teds1517.rename(columns = {\"CBSA2010\":\"CBSA\",\n",
    "                          \"ADMYR\":\"YEAR\",\n",
    "                          \"SERVICES\":\"SERVSETA\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to just the 0/1 drug flag variables\n",
    "flags = teds1517.filter(regex='FLG$', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the flag variables to calculate the number of drugs recorded for each individual\n",
    "NUMSUBS = flags.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate flag variables back into the 2015-17 data\n",
    "teds_wflgs = pd.concat([teds1517, NUMSUBS], axis = 1)\n",
    "teds_wflgs.rename(columns={0:'NUMSUBS'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the 2015-17 columns for appending\n",
    "col_names = list(teds14.columns)\n",
    "teds_reorder = teds_wflgs[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all years together\n",
    "teds_all_temp = teds_reorder.append(teds14)\n",
    "teds_all = teds_all_temp.append(teds13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subset of columns\n",
    "teds_sm = teds_all.loc[:,['CASEID','YEAR','AGE','GENDER','RACE','ETHNIC','MARSTAT','EDUC','EMPLOY','VET','LIVARAG',\n",
    "                         'ARRESTS','DIVISION','SERVSETA','PSOURCE','NOPRIOR','SUB1','FRSTUSE1','NUMSUBS','PSYPROB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the first substance was \"None\"\n",
    "teds_sm_temp = teds_sm[teds_sm.SUB1 != 1]\n",
    "# Remove rows where number of prior treatments is NA (target variable)\n",
    "teds_sm1 = teds_sm_temp[teds_sm_temp.NOPRIOR != -9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode age group variable\n",
    "def age_groups(series):\n",
    "    # 12-17 years\n",
    "    if series == 1 or series == 2:\n",
    "        return '12-17 years'\n",
    "    # 18-29 years\n",
    "    elif series == 3 or series == 4 or series == 5:\n",
    "        return '18-29 years'\n",
    "    # 30-39 years\n",
    "    elif series == 6 or series == 7:\n",
    "        return '30-39 years'\n",
    "    # 40-49 years\n",
    "    elif series == 8 or series == 9:\n",
    "        return '40-49 years'\n",
    "    # 50-64 years\n",
    "    elif series == 10 or series == 11:\n",
    "        return '50-64 years'\n",
    "    # 65+ years\n",
    "    elif series == 12:\n",
    "        return '65+ years'\n",
    "    \n",
    "teds_sm1.loc[:, 'age_group'] = teds_sm1.AGE.apply(age_groups)\n",
    "\n",
    "# Change variable to an ordered factor\n",
    "teds_sm1.loc[:, 'age_group'] = pd.Categorical(teds_sm1['age_group'], categories = ['12-17 years', '18-29 years', '30-39 years',\n",
    "                                                                                   '40-49 years', '50-64 years', '65+ years'], ordered = True)\n",
    "\n",
    "# Change variable to an ordered factor with values as numbers\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'age_group'], sort = True)\n",
    "teds_sm1.loc[:, 'age_group'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode primary substance variable\n",
    "def sub(series):\n",
    "    if series == 2:\n",
    "        return 'Alcohol'\n",
    "    elif series == 3:\n",
    "        return 'Cocaine/Crack'\n",
    "    elif series == 4:\n",
    "        return 'Marijuana/Hashish'\n",
    "    elif series == 5:\n",
    "        return 'Heroin'\n",
    "    elif series == 6 or series == 7:\n",
    "        return 'Opioids or Methadone'\n",
    "    elif series == 10:\n",
    "        return 'Methamphetamine'\n",
    "    elif series == 11 or series == 12:\n",
    "        return 'Other Amphetamines or Stimulants'\n",
    "    elif series == 13 or series == 14:\n",
    "        return 'Benzodiazepines or Tranquilizers'\n",
    "    elif series == 8 or series == 9:\n",
    "        return 'PCP or Other Hallucinogens'\n",
    "    elif series >= 15 & series <= 20:\n",
    "        return 'Other'\n",
    "\n",
    "teds_sm1.loc[:, 'drug'] = teds_sm1.SUB1.apply(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode gender variable\n",
    "def gen_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Male'\n",
    "    elif series == 2:\n",
    "        return 'Female'\n",
    "    \n",
    "teds_sm1.loc[:, 'gender'] = teds_sm1.GENDER.apply(gen_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record race variable\n",
    "def race_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Alaska Native'\n",
    "    elif series == 2:\n",
    "        return 'American Indian'\n",
    "    elif series == 3 or series == 9:\n",
    "        return 'Hawaii, Pacific Islander'\n",
    "    elif series == 4:\n",
    "        return 'Black'\n",
    "    elif series == 5:\n",
    "        return 'White'\n",
    "    elif series == 6:\n",
    "        return 'Asian'\n",
    "    elif series == 7:\n",
    "        return 'Other race'\n",
    "    elif series == 8:\n",
    "        return 'Two or more races'\n",
    "    \n",
    "teds_sm1.loc[:, 'race'] = teds_sm1.RACE.apply(race_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode ethnicity variable\n",
    "def ethnic_rc(series):\n",
    "    if (series >= 1 or series <= 3) or series == 5:\n",
    "        return 'Hispanic'\n",
    "    elif series == 4:\n",
    "        return 'Non-Hispanic'\n",
    "    \n",
    "teds_sm1.loc[:, 'ethnic'] = teds_sm1.ETHNIC.apply(ethnic_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode service setting variable\n",
    "def servseta_rc(series):\n",
    "    if series == 1 or series == 2:\n",
    "        return 'Detox'\n",
    "    elif series >= 3 and series <= 5:\n",
    "        return 'Rehab/Residential'\n",
    "    elif series >= 6 and series <= 8:\n",
    "        return 'Ambulatory'\n",
    "\n",
    "teds_sm1.loc[:, 'servseta'] = teds_sm1.SERVSETA.apply(servseta_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode marital status variable\n",
    "def marstat_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Never Married'\n",
    "    elif series == 2:\n",
    "        return 'Married'\n",
    "    elif series == 3:\n",
    "        return 'Separated'\n",
    "    elif series == 4:\n",
    "        return 'Divorced or Widowed'\n",
    "\n",
    "teds_sm1.loc[:, 'marstat'] = teds_sm1.MARSTAT.apply(marstat_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode employment status variable\n",
    "def employ_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Full-time'\n",
    "    elif series == 2:\n",
    "        return 'Part-time'\n",
    "    elif series == 3:\n",
    "        return 'Unemployed'\n",
    "    elif series == 4:\n",
    "        return 'Not in the labor force'\n",
    "    \n",
    "teds_sm1.loc[:, 'employ'] = teds_sm1.EMPLOY.apply(employ_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode veteran variable\n",
    "def vet_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Veteran'\n",
    "    elif series == 2:\n",
    "        return 'Not a Veteran'\n",
    "    \n",
    "teds_sm1.loc[:, 'vet'] = teds_sm1.VET.apply(vet_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode living arrangement variable\n",
    "def livarag_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Homeless'\n",
    "    elif series == 2:\n",
    "        return 'Dependent Living'\n",
    "    elif series == 3:\n",
    "        return 'Independent Living'\n",
    "\n",
    "teds_sm1.loc[:, 'livarag'] = teds_sm1.LIVARAG.apply(livarag_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode arrests variable\n",
    "def arrests_rc(series):\n",
    "    if series == 0:\n",
    "        return 'None'\n",
    "    elif series == 1:\n",
    "        return 'Once'\n",
    "    elif series == 2:\n",
    "        return '2 or more times'\n",
    "    \n",
    "teds_sm1.loc[:, 'arrests'] = teds_sm1.ARRESTS.apply(arrests_rc)\n",
    "\n",
    "# Change variable to an ordered factor variable\n",
    "teds_sm1.loc[:, 'arrests'] = pd.Categorical(teds_sm1['arrests'], categories = ['None', 'Once',\n",
    "                                                                              '2 or more times'],\n",
    "                                           ordered = True)\n",
    "\n",
    "# Change variable to an ordered factor with values as numbers\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'arrests'], sort = True)\n",
    "teds_sm1.loc[:, 'arrests'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode division variable\n",
    "def division_rc(series):\n",
    "    if series == 0:\n",
    "        return 'US Territories'\n",
    "    elif series == 1:\n",
    "        return 'New England'\n",
    "    elif series == 2:\n",
    "        return 'Mid Atlantic'\n",
    "    elif series == 3:\n",
    "        return 'East North Central'\n",
    "    elif series == 4:\n",
    "        return 'West North Central'\n",
    "    elif series == 5:\n",
    "        return 'South Atlantic'\n",
    "    elif series == 6:\n",
    "        return 'East South Central'\n",
    "    elif series == 7:\n",
    "        return 'West South Central'\n",
    "    elif series == 8:\n",
    "        return 'Mountain'\n",
    "    elif series == 9:\n",
    "        return 'Pacific'\n",
    "    \n",
    "teds_sm1.loc[:, 'division'] = teds_sm1.DIVISION.apply(division_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode referral source variable\n",
    "def psource_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Self-referral'\n",
    "    elif series == 2:\n",
    "        return 'Alcohol or Drug Care Professional'\n",
    "    elif series == 3:\n",
    "        return 'Other Health Care Professional'\n",
    "    elif series == 4:\n",
    "        return 'School Referral'\n",
    "    elif series == 5:\n",
    "        return 'Employer Referral'\n",
    "    elif series == 6:\n",
    "        return 'Community Referral'\n",
    "    elif series == 7:\n",
    "        return 'Court Referral'\n",
    "    \n",
    "teds_sm1.loc[:, 'psource'] = teds_sm1.PSOURCE.apply(psource_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode number of prior treatment encounters\n",
    "def noprior_rc(series):\n",
    "    if series == 0:\n",
    "        return 0\n",
    "    elif series >= 1:\n",
    "        return 1\n",
    "    \n",
    "teds_sm1.loc[:, 'noprior'] = teds_sm1.NOPRIOR.apply(noprior_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode year variable\n",
    "def year_rc(series):\n",
    "    if series == 2013:\n",
    "        return '2013'\n",
    "    elif series == 2014:\n",
    "        return '2014'\n",
    "    elif series == 2015:\n",
    "        return '2015'\n",
    "    elif series == 2016:\n",
    "        return '2016'\n",
    "    elif series == 2017:\n",
    "        return '2017'\n",
    "    \n",
    "teds_sm1.loc[:, 'year'] = teds_sm1.YEAR.apply(year_rc)\n",
    "\n",
    "\n",
    "# Change year to an ordered factor\n",
    "teds_sm1.loc[:, 'year'] = pd.Categorical(teds_sm1['year'], categories = ['2013', '2014', '2015', '2016', '2017'],\n",
    "                                           ordered = True)\n",
    "\n",
    "# Convert year to factor with numeric value\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'year'], sort = True)\n",
    "teds_sm1.loc[:, 'year'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode first use variable\n",
    "def frstuse_rc(series):\n",
    "    if series == 1:\n",
    "        return '11 years or under'\n",
    "    elif series == 2:\n",
    "        return '12-14 years'\n",
    "    elif series == 3:\n",
    "        return '15-17 years'\n",
    "    elif series == 4:\n",
    "        return '18-20 years'\n",
    "    elif series == 5:\n",
    "        return '21-24 years'\n",
    "    elif series == 6:\n",
    "        return '25-29 years'\n",
    "    elif series == 7:\n",
    "        return '30 years or older'\n",
    "    \n",
    "teds_sm1.loc[:, 'frstuse'] = teds_sm1.FRSTUSE1.apply(frstuse_rc)\n",
    "\n",
    "# Change first use into an ordered factor\n",
    "teds_sm1.loc[:, 'frstuse'] = pd.Categorical(teds_sm1['frstuse'], categories = ['11 years or under', '12-14 years', '15-17 years',\n",
    "                                                                               '18-20 years', '21-24 years', '25-29 years',\n",
    "                                                                               '30 years or older'], ordered = True)\n",
    "\n",
    "# Convert year to factor with numeric value\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'frstuse'], sort = True)\n",
    "teds_sm1.loc[:, 'frstuse'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode mental illness variable\n",
    "def psyprob_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Has mental illness'\n",
    "    elif series == 2:\n",
    "        return 'Does not have mental illness'\n",
    "    \n",
    "teds_sm1.loc[:, 'psyprob'] = teds_sm1.PSYPROB.apply(psyprob_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode number of substances variable\n",
    "def numsubs_rc(series):\n",
    "    if series == 0:\n",
    "        return 'Zero substances'\n",
    "    elif series == 1:\n",
    "        return 'One substance'\n",
    "    elif series == 2:\n",
    "        return 'Two substances'\n",
    "    elif series == 3:\n",
    "        return 'Three substances'\n",
    "    \n",
    "teds_sm1.loc[:, 'numsubs'] = teds_sm1.NUMSUBS.apply(numsubs_rc)\n",
    "\n",
    "# Change first use into an ordered factor\n",
    "teds_sm1.loc[:, 'numsubs'] = pd.Categorical(teds_sm1['numsubs'], categories = ['Zero substances', 'One substance',\n",
    "                                                                               'Two substances', \"Three substances\"], ordered = True)\n",
    "\n",
    "# Convert year to factor with numeric value\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'numsubs'], sort = True)\n",
    "teds_sm1.loc[:, 'numsubs'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to fewer variables, mostly dropping those with many missing values\n",
    "teds_clean = teds_sm1.drop(['CASEID', 'YEAR', 'AGE', 'GENDER', 'RACE', 'ETHNIC', 'MARSTAT',\n",
    "                            'EDUC', 'EMPLOY', 'VET', 'LIVARAG', 'ARRESTS', 'DIVISION', 'SERVSETA',\n",
    "                            'PSOURCE', 'NOPRIOR', 'SUB1', 'FRSTUSE1', 'NUMSUBS', 'PSYPROB'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for unordered categorical variables\n",
    "teds_clean = pd.get_dummies(teds_clean, columns=['drug', 'gender', 'race', 'ethnic', 'servseta', 'marstat', 'employ', 'livarag', \n",
    "                                             'division', 'psource', 'psyprob', 'vet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data to just 2017\n",
    "# Attempted analyses with 2015-17 as well but the results were about the same as without the extra years\n",
    "teds2017 = teds_clean.query('year == 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop response variable and year since only 2017 will be used in final modeling\n",
    "data = teds2017.drop(columns = ['noprior', 'year'])\n",
    "# Create data frame with just the response variable\n",
    "response = teds2017.loc[:,['noprior']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing data witn mode\n",
    "my_imputer = SimpleImputer()\n",
    "data_imputed = pd.DataFrame(my_imputer.fit_transform(data))\n",
    "data_imputed.columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change response and predictor data frames to numpy arrays\n",
    "data_imp_np = np.array(data_imputed)\n",
    "response_np = np.array(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create holdout data set and keep remaining 80% in one data frame\n",
    "# Used stratefied random sampling because there was class imbalance\n",
    "sss = StratifiedShuffleSplit(n_splits = 2, test_size=0.2, random_state=0)\n",
    "\n",
    "sss.get_n_splits(data_imp_np, response_np)\n",
    "\n",
    "for train_index, test_index in sss.split(data_imp_np, response_np):\n",
    "    x_train_temp, x_test = data_imp_np[train_index], data_imp_np[test_index]\n",
    "    y_train_temp, y_test = response_np[train_index], response_np[test_index]\n",
    "\n",
    "# Split the remaining data into a training and validation data set (50% and 30% respectively)\n",
    "sss_valid = StratifiedShuffleSplit(n_splits = 2, test_size = 0.3, random_state = 10)  \n",
    "    \n",
    "for train_index, test_index in sss_valid.split(x_train_temp, y_train_temp):\n",
    "    x_train, x_validation = x_train_temp[train_index], x_train_temp[test_index]\n",
    "    y_train, y_validation = y_train_temp[train_index], y_train_temp[test_index]\n",
    "\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_validation = np.array(x_validation)\n",
    "y_validation = np.array(y_validation)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-defined function to create formatted confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"\\nNormalized confusion matrix\")\n",
    "    else:\n",
    "        print('\\nConfusion matrix, without normalization')\n",
    "\n",
    "    print ()\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize = 15)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=20, fontsize = 14)\n",
    "    plt.yticks(tick_marks, classes, fontsize = 14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize = 14)\n",
    "    plt.xlabel('Predicted label', fontsize = 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run logistic regression model as a baseline\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "valid_predict_logreg = logreg_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_validation, valid_predict_logreg))\n",
    "\n",
    "# Assign classes\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_logreg = confusion_matrix(y_validation, valid_predict_logreg)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_logreg, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Logistic Regression')\n",
    "\n",
    "# Results: Accuracy is 68%, but very bad accuracy for identifying first admission patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lasso regression grid search across multiple penalties\n",
    "penalties = [0.2, 0.5, 0.7, 0.9]\n",
    "\n",
    "results_lasso = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    c_value = penalties[i]\n",
    "\n",
    "    lasso_model = LogisticRegression(penalty = 'l1', C = c_value)\n",
    "\n",
    "    lasso_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_lasso = lasso_model.predict(x_validation)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_lasso, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_lasso, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'c'] = c_value\n",
    "    class_report.loc[:, 'model'] = 'Lasso Regression'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_lasso = pd.concat([results_lasso, class_report], axis = 0)\n",
    "\n",
    "# Results: Results were little better than logistic regression and varied little when penalty was changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression grid search across multiple penalties\n",
    "penalties = [0.2, 0.5, 0.7, 0.9]\n",
    "\n",
    "results_ridge = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    c_value = penalties[i]\n",
    "\n",
    "    ridge_model = LogisticRegression(penalty = 'l2', C = c_value)\n",
    "\n",
    "    ridge_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_ridge = ridge_model.predict(x_validation)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_ridge, output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_ridge, output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'c'] = c_value\n",
    "    class_report.loc[:, 'model'] = 'Ridge Regression'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_ridge = pd.concat([results_ridge, class_report], axis = 0)\n",
    "    \n",
    "# Results: Results were little better than logistic regression and varied little when penalty was changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run default gradient boosted trees model to get baseline accuracy and feature importances\n",
    "gbt_model = GradientBoostingClassifier(random_state=75)\n",
    "gbt_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "valid_predict_gbt = gbt_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation metrics and feature importances to narrow down variables I need\n",
    "print(classification_report(y_validation, valid_predict_gbt))\n",
    "\n",
    "# Print feature importances to subset data set to more important variables\n",
    "print(pd.DataFrame({'features': data_imputed.columns,\n",
    "                    'importances': gbt_model.feature_importances_}).sort_values(['importances'], ascending = 0))\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_gbt = confusion_matrix(y_validation, valid_predict_gbt)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_gbt, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a medium-sized data set with all variables above 0.005 in importance\n",
    "x_train_sm = x_train[:, [7, 0, 3, 45, 2, 49, 43, 26, 48, 8, 56, 41, 39, 40, 25, 37, 1, 44, 11, 4, 42, 58, 33, 30, 57, 27, 47, 28]]\n",
    "x_validation_sm = x_validation[:, [7, 0, 3, 45, 2, 49, 43, 26, 48, 8, 56, 41, 39, 40, 25, 37, 1, 44, 11, 4, 42, 58, 33, 30, 57, 27, 47, 28]]\n",
    "x_test_sm = x_test[:, [7, 0, 3, 45, 2, 49, 43, 26, 48, 8, 56, 41, 39, 40, 25, 37, 1, 44, 11, 4, 42, 58, 33, 30, 57, 27, 47, 28]]\n",
    "features_sm = data_imputed.iloc[:, [7, 0, 3, 45, 2, 49, 43, 26, 48, 8, 56, 41, 39, 40, 25, 37, 1, 44, 11, 4, 42, 58, 33, 30, 57, 27, 47, 28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression with a smaller number of variables, grid search for penalties most accurate for larger data set\n",
    "penalties = [0.5, 0.9]\n",
    "\n",
    "results_ridge_sm = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,2):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    c_value = penalties[i]\n",
    "\n",
    "    ridge_model = LogisticRegression(penalty = 'l2', C = c_value)\n",
    "\n",
    "    ridge_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_ridge = ridge_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_ridge, output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_ridge, output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'c'] = c_value\n",
    "    class_report.loc[:, 'model'] = 'Ridge Regression'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_ridge_sm = pd.concat([results_ridge_sm, class_report], axis = 0)\n",
    "    \n",
    "# Results: Accuracy dropped to 67% with smaller number of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ridge_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy of default model with medium and large data frames\n",
    "# Run default gradient boosted trees model to get baseline accuracy and feature importances\n",
    "gbt_model_sm = GradientBoostingClassifier(random_state=75)\n",
    "gbt_model_sm.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_gbt_sm = gbt_model_sm.predict(x_validation_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics are the same as with the full data set so stick with the limited data set\n",
    "print(classification_report(y_validation, valid_predict_gbt_sm))\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_gbt_sm = confusion_matrix(y_validation, valid_predict_gbt_sm)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_gbt_sm, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Gradient Boosted Trees')\n",
    "\n",
    "# Results: Accuracy increased to 70%, but first treatment episode accuracy did not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosted trees, grid search varying the number of estimators\n",
    "n_estimators = [150, 200, 300]\n",
    "\n",
    "results_gbt_nEst = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    est_value = n_estimators[i]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, n_estimators = est_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'n_estimators'] = est_value\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_nEst = pd.concat([results_gbt_nEst, class_report], axis = 0)\n",
    "    \n",
    "# Results: Accuracy increased with the number of estimators, but 200 and 300 were not different enough to justify the extra processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_nEst\n",
    "# Minimal increase in accuracy for 300 and 200 instead of 150 so will stick with 150 for further testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient boosted trees, varying the maximum depth of the tree\n",
    "max_depth = [5, 7, 9, 15]\n",
    "\n",
    "results_gbt_max_depth = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    max_depth_value = max_depth[i]\n",
    "    \n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, n_estimators = 200, max_depth = max_depth_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'max_depth'] = max_depth_value\n",
    "    class_report.loc[:, 'n_estimators'] = 200\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_max_depth = pd.concat([results_gbt_max_depth, class_report], axis = 0)\n",
    "    \n",
    "# Results: Accuracy increased with the depth of the tree, but did not increase enough from 7 to 9 to justify extra processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient boosted trees, grid search varying the learning rate\n",
    "# Going to compare the results of this to the results from n_estimators because these hyperparameters present a trade off\n",
    "learning_rate = [0.05, 0.15, 0.3, 0.35]\n",
    "\n",
    "results_gbt_learn_rate = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    learn_rate_value = learning_rate[i]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, learning_rate = learn_rate_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'learning_rate'] = learn_rate_value\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_learn_rate = pd.concat([results_gbt_learn_rate, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy optimal with a learning rate of 0.3, results more accurate than with n_estimators altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient boosted trees, grid search varying learning rate and maximum depth of trees\n",
    "learning_rate = [0.05, 0.15, 0.3]\n",
    "max_depth = [5, 7, 9]\n",
    "\n",
    "results_gbt_lrate_depth = pd.DataFrame([])\n",
    "\n",
    "for i, j in itertools.product(range(0,3), range(0,3)):\n",
    "    \n",
    "    print(i)\n",
    "    print(j)\n",
    "    \n",
    "    max_depth_value = max_depth[i]\n",
    "    \n",
    "    learning_rate_value = learning_rate[j]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, max_depth = max_depth_value,\n",
    "                                           learning_rate = learning_rate_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'max_depth'] = max_depth_value\n",
    "    class_report.loc[:, 'learning_rate'] = learning_rate_value\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_lrate_depth = pd.concat([results_gbt_lrate_depth, class_report], axis = 0)\n",
    "\n",
    "# Results: Optimal results with max_depth = 7 and learning_rate = 0.3\n",
    "# Accuracy = 0.72, F1-score for 1st treatment: 0.54, F1-score for 2+ treatments: 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_gbt_lrate_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient boosted trees, attempting early stopping with minimum impurity decrease\n",
    "min_imp_dec = [0.25, 0.5, 0.1]\n",
    "\n",
    "results_gbt_imp_dec = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    min_imp_value = min_imp_dec[i]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, learning_rate = 0.3, \n",
    "                                           min_impurity_decrease = min_imp_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'min_impurity_decrease'] = min_imp_value\n",
    "    class_report.loc[:, 'learning_rate'] = 0.3\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_imp_dec = pd.concat([results_gbt_imp_dec, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy decreased by several points on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_imp_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosted trees, grid search varying maximum depth and max_features\n",
    "max_depth = [0.5, 0.1]\n",
    "max_features = [7, 10, 15]\n",
    "\n",
    "results_gbt_feat_maxdepth = pd.DataFrame([])\n",
    "\n",
    "for i, j in itertools.product(range(0,2), range(0,3)):\n",
    "    \n",
    "    max_depth_value = max_depth[i]\n",
    "    \n",
    "    max_feat_value = max_features[j]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, max_depth = max_depth_value,\n",
    "                                           learning_rate = 0.3, max_features = max_feat_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'max_depth'] = min_imp_dec_value\n",
    "    class_report.loc[:, 'max_features'] = max_feat_value\n",
    "    class_report.loc[:, 'learning_rate'] = 0.3\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_feat_maxdepth = pd.concat([results_gbt_feat_maxdepth, class_report], axis = 0)\n",
    "\n",
    "# Results: Adding a maximum feature parameter changed the model metrics very little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_feat_maxdepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Boosted Trees, grid search with varying sub-samples\n",
    "sub_sample = [0.8, 0.9, 0.95]\n",
    "\n",
    "results_stoch_grad = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    subsample_value = sub_sample[i]\n",
    "\n",
    "    stoch_grad_model = GradientBoostingClassifier(random_state = 75, learning_rate = 0.3, max_depth = 9,\n",
    "                                          subsample = subsample_value)\n",
    "\n",
    "    stoch_grad_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_stoch_grad = stoch_grad_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_stoch_grad, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'subsample'] = subsample_value\n",
    "    class_report.loc[:, 'learning_rate'] = 0.3\n",
    "    class_report.loc[:, 'max_depth'] = 9\n",
    "    class_report.loc[:, 'model'] = 'Stochastic Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_stoch_grad = pd.concat([results_stoch_grad, class_report], axis = 0)\n",
    "\n",
    "# Results: Adding a sub-sampling parameter changed the model metrics very little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stoch_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a default random forest model\n",
    "rf_model_default = RandomForestClassifier(random_state=75)\n",
    "rf_model_default.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_rf_def = rf_model_default.predict(x_validation_sm)\n",
    "\n",
    "# Results: Accuracy is 69% with F1-score of 52% for first treatment and 77% for 2+ treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_validation, valid_predict_rf_def))\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_rf_def = confusion_matrix(y_validation, valid_predict_rf_def)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_rf_def, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, grid search varying the number of estimators\n",
    "n_estimators = [200, 300, 350]\n",
    "\n",
    "results_rf_n_est = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    n_est_value = n_estimators[i]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = n_est_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'n_estimators'] = n_est_value\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_n_est = pd.concat([results_rf_n_est, class_report], axis = 0)\n",
    "\n",
    "# Results: An increase in accuracy until 300, enough to warrant keeping 300 over 200 although similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_n_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, grid search varying the minimum samples per split\n",
    "min_samples_split = [5, 9, 12]\n",
    "\n",
    "results_rf_min_samp = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    min_samp_split_value = min_samples_split[i]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                     min_samples_split = min_samp_split_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'min_samples_split'] = min_samp_split_value\n",
    "    class_report.loc[:, 'n_estimators'] = 300\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_min_samp = pd.concat([results_rf_min_samp, class_report], axis = 0)\n",
    "    \n",
    "# Results: Accuracy optimized at min_samples_split = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_min_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest, testing early stopping with a grid search on minimum impurity decrease per split\n",
    "min_impurity_decrease = [0.03, 0.05, 0.1]\n",
    "\n",
    "results_rf_imp_dec = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    min_imp_dec_value = min_impurity_decrease[i]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                     min_impurity_decrease = min_imp_dec_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'min_impurity_decrease'] = min_imp_dec_value\n",
    "    class_report.loc[:, 'n_estimators'] = 300\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_imp_dec = pd.concat([results_rf_imp_dec, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy dropped a large amount to mid-60%s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_imp_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest, grid search varying the maximum features and minimum samples per split\n",
    "max_features = [7, 10, 15]\n",
    "min_samples_split = [9, 12]\n",
    "\n",
    "results_rf_feat_samp_split = pd.DataFrame([])\n",
    "\n",
    "for i, j in itertools.product(range(0,3), range(0,2)):\n",
    "    \n",
    "    print(i)\n",
    "    print(j)\n",
    "    \n",
    "    max_feat_value = max_features[i]\n",
    "    min_samp_split_value = min_samples_split[j]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                     max_features = max_feat_value, min_samples_split = min_samp_split_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'n_estimators'] = 300\n",
    "    class_report.loc[:, 'max_features'] = max_feat_value\n",
    "    class_report.loc[:, 'min_samples_split'] = min_samp_split_value\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_feat_samp_split = pd.concat([results_rf_feat_samp_split, class_report], axis = 0)\n",
    "\n",
    "# Results: The above changes attempted did not increase accuracy above the other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_feat_samp_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest, varying the penalty/weight put on wrong answers for 0, which is more commonly misclassified\n",
    "# Also varying minimum samples per split\n",
    "min_samples_split = [9, 12]\n",
    "weight = [1.5, 2, 2.5, 3]\n",
    "\n",
    "results_rf_feat_samp_split = pd.DataFrame([])\n",
    "\n",
    "for i, j in itertools.product(range(0,2), range(0,4)):\n",
    "    \n",
    "    print(i)\n",
    "    print(j)\n",
    "    \n",
    "    max_feat_value = n_estimators[i]\n",
    "    weight_value = weight[j]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                     class_weight = {0:weight_value}, min_samples_split = min_samp_split_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'n_estimators'] = 300\n",
    "    class_report.loc[:, 'weight_zero'] = weight_value\n",
    "    class_report.loc[:, 'min_samples_split'] = min_samp_split_value\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_feat_samp_split = pd.concat([results_rf_feat_samp_split, class_report], axis = 0)\n",
    "\n",
    "# Results: Classification of 0 values greatly improved without sacrificing much overall accuracy\n",
    "# Accuracy = 0.70, F1-score for 0 = 0.62, F1-score for 1 = 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_feat_samp_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors, grid search varying k with Euclidean distance\n",
    "k = [5, 8, 12, 15]\n",
    "\n",
    "knn_euclidean = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    k_value = k[i]\n",
    "\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = k_value, p = 2, n_jobs = 7)\n",
    "\n",
    "    knn_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_knn = knn_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_knn, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_knn, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'k'] = k_value\n",
    "    class_report.loc[:, 'distance_metric'] = 'Euclidean'\n",
    "    class_report.loc[:, 'model'] = 'K-Nearest Neighbors'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    knn_euclidean = pd.concat([knn_euclidean, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy dropped from mid to high 60s with lower F1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors, grid search varying k for Minkowski distance\n",
    "k = [5, 8, 12, 15]\n",
    "\n",
    "knn_minkowski = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    k_value = k[i]\n",
    "\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = k_value, n_jobs = 7)\n",
    "\n",
    "    knn_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_knn = knn_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_knn, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_knn, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'k'] = k_value\n",
    "    class_report.loc[:, 'distance_metric'] = 'Minkowski'\n",
    "    class_report.loc[:, 'model'] = 'K-Nearest Neighbors'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    knn_minkowski = pd.concat([knn_minkowski, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy looked virtually identical to Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_minkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model for each model type\n",
    "## Lasso Regression\n",
    "lasso_model_final = LogisticRegression(penalty = 'l1', C = 0.5)\n",
    "lasso_model_final.fit(x_train, np.ravel(y_train, order='C'))\n",
    "valid_predict_lasso_final = lasso_model_final.predict(x_validation)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_lasso = confusion_matrix(y_validation, valid_predict_lasso_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_lasso, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Lasso Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge Regression\n",
    "ridge_model_final = LogisticRegression(penalty = 'l2', C = 0.5)\n",
    "ridge_model_final.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_ridge_final = ridge_model_final.predict(x_validation_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_ridge = confusion_matrix(y_validation, valid_predict_ridge_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_ridge, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Ridge Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosted Trees\n",
    "gbt_model_final = GradientBoostingClassifier(random_state = 75, learning_rate = 0.3, max_depth = 7)\n",
    "gbt_model_final.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_gbt_final = gbt_model_final.predict(x_validation_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_gbt = confusion_matrix(y_validation, valid_predict_gbt_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_gbt, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "rf_model_final = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                        class_weight = {0:2}, min_samples_split = 12)\n",
    "rf_model_final.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_rf_final = rf_model_final.predict(x_validation_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_rf = confusion_matrix(y_validation, valid_predict_rf_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_rf, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors\n",
    "knn_model_final = KNeighborsClassifier(n_neighbors = 12, n_jobs = 7)\n",
    "knn_model_final.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_knn_final = knn_model_final.predict(x_validation_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_knn = confusion_matrix(y_validation, valid_predict_knn_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_knn, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Building and printing ROC curves for all final models\n",
    "classes = ['First', 'Two or More']\n",
    "\n",
    "probs1 = lasso_model_final.predict_proba(x_validation)\n",
    "probs1 = probs1[:, 1]\n",
    "\n",
    "probs2 = rf_model_final.predict_proba(x_validation_sm)\n",
    "probs2 = probs2[:, 1]\n",
    "\n",
    "probs3 = gbt_model_final.predict_proba(x_validation_sm)\n",
    "probs3 = probs3[:, 1]\n",
    "\n",
    "probs4 = logreg_model.predict_proba(x_validation)\n",
    "probs4 = probs4[:, 1]\n",
    "\n",
    "probs5 = knn_model_final.predict_proba(x_validation_sm)\n",
    "probs5 = probs5[:, 1]\n",
    "\n",
    "probs6 = ridge_model_final.predict_proba(x_validation_sm)\n",
    "probs6 = probs6[:, 1]\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs3)\n",
    "auc = metrics.roc_auc_score(y_validation, probs3)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Gradient Boosted Trees, auc=\"+str(round(auc, 2)), color = 'red')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs2)\n",
    "auc = metrics.roc_auc_score(y_validation, probs2)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Random Forest, auc=\"+str(round(auc, 2)), color = 'blue')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs5)\n",
    "auc = metrics.roc_auc_score(y_validation, probs5)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"K-Nearest Neighbors, auc=\"+str(round(auc, 2)), color = 'darkorchid')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs4)\n",
    "auc = metrics.roc_auc_score(y_validation, probs4)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, auc=\"+str(round(auc, 2)), color = 'gold')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs1)\n",
    "auc = metrics.roc_auc_score(y_validation, probs1)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Lasso Regression, auc=\"+str(round(auc, 2)), color = 'darkorange')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs6)\n",
    "auc = metrics.roc_auc_score(y_validation, probs6)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Ridge Regression, auc=\"+str(round(auc, 2)), color = 'green')\n",
    "\n",
    "plt.legend(loc=0, fontsize = 'x-large')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize = 35)\n",
    "plt.xticks(fontsize = 25)\n",
    "plt.yticks(fontsize = 25)\n",
    "plt.xlabel('False Positive Rate', fontsize = 30)\n",
    "plt.ylabel('True Positive Rate', fontsize = 30)\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 15\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('NumPriorTreat_ROC_Curve_Comp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Chosen: Random Forest with min_samples_split = 12, n_estimators = 300, and a weight of 2 on misclassifications of zero\n",
    "# Above model shows lower accuracy on the ROC curve than gradient boosted trees but is the only model that classified 0s significantly higher than chance\n",
    "# Testing model with final holdout data set\n",
    "valid_predict_rf_ho = rf_model_final.predict(x_test_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_rf_ho = confusion_matrix(y_test, valid_predict_rf_ho)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_rf, classes=class_names, normalize=True,\n",
    "                      title='Normalized Confusion Matrix, Random Forest, Holdout Data')\n",
    "\n",
    "pd.DataFrame(classification_report(y_test, valid_predict_rf_ho, \n",
    "                                   output_dict = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
